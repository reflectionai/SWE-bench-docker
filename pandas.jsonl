{"repo":"pandas-dev\/pandas","instance_id":"pandas-dev__pandas-39807","base_commit":"fc9fdba6592bdb5d0d1147ce4d65639acd897565","test_patch":"diff --git a\/pandas\/tests\/io\/formats\/test_style.py b\/pandas\/tests\/io\/formats\/test_style.py\n--- a\/pandas\/tests\/io\/formats\/test_style.py\n+++ b\/pandas\/tests\/io\/formats\/test_style.py\n@@ -254,8 +254,8 @@ def test_index_name(self):\n             ],\n             [\n                 {\"class\": \"index_name level0\", \"type\": \"th\", \"value\": \"A\"},\n-                {\"class\": \"blank\", \"type\": \"th\", \"value\": \"\"},\n-                {\"class\": \"blank\", \"type\": \"th\", \"value\": \"\"},\n+                {\"class\": \"blank col0\", \"type\": \"th\", \"value\": \"\"},\n+                {\"class\": \"blank col1\", \"type\": \"th\", \"value\": \"\"},\n             ],\n         ]\n \n@@ -293,7 +293,7 @@ def test_multiindex_name(self):\n             [\n                 {\"class\": \"index_name level0\", \"type\": \"th\", \"value\": \"A\"},\n                 {\"class\": \"index_name level1\", \"type\": \"th\", \"value\": \"B\"},\n-                {\"class\": \"blank\", \"type\": \"th\", \"value\": \"\"},\n+                {\"class\": \"blank col0\", \"type\": \"th\", \"value\": \"\"},\n             ],\n         ]\n \n@@ -1537,7 +1537,7 @@ def test_mi_sparse_index_names(self):\n         expected = [\n             {\"class\": \"index_name level0\", \"value\": \"idx_level_0\", \"type\": \"th\"},\n             {\"class\": \"index_name level1\", \"value\": \"idx_level_1\", \"type\": \"th\"},\n-            {\"class\": \"blank\", \"value\": \"\", \"type\": \"th\"},\n+            {\"class\": \"blank col0\", \"value\": \"\", \"type\": \"th\"},\n         ]\n \n         assert head == expected\n","problem_statement":"BUG: `Style` index name row does not label column class\n- [x] I have checked that this issue has not already been reported.\r\n\r\n- [x] I have confirmed this bug exists on the latest version of pandas.\r\n\r\n- [x] (optional) I have confirmed this bug exists on the master branch of pandas.\r\n\r\n---\r\n\r\nThe `Styler` ignores column class on the `index_name` row and just inputs `blank`, which is a pain for controlling `table_styles` using column selectors.\r\n\r\n```\r\ndf3 = pd.DataFrame(0, index=['a'], columns=['A','B'])\r\ndf3.index.name = 'foo'\r\nprint(df3.style.render())\r\n```\r\n\r\n```\r\n<style type=\"text\/css\">\r\n<\/style>\r\n<table id=\"T_a6821_\">\r\n  <thead>\r\n    <tr>\r\n      <th class=\"blank level0\" ><\/th>\r\n      <th class=\"col_heading level0 col0\" >A<\/th>\r\n      <th class=\"col_heading level0 col1\" >B<\/th>\r\n    <\/tr>\r\n    <tr>\r\n      <th class=\"index_name level0\" >foo<\/th>\r\n      <th class=\"blank\" ><\/th>\r\n      <th class=\"blank\" ><\/th>\r\n    <\/tr>\r\n  <\/thead>\r\n  <tbody>\r\n    <tr>\r\n      <th id=\"T_a6821_level0_row0\" class=\"row_heading level0 row0\" >a<\/th>\r\n      <td id=\"T_a6821_row0_col0\" class=\"data row0 col0\" >0<\/td>\r\n      <td id=\"T_a6821_row0_col1\" class=\"data row0 col1\" >0<\/td>\r\n    <\/tr>\r\n  <\/tbody>\r\n<\/table>\r\n```\r\n\r\nInternal mechanics should be fixed to add the col index class.\r\n\n","hints_text":"Hii, I am new to open source and decided to fix this bug because it is labeled \"good first issue\". But I am facing difficulty in starting. \r\nIn which file should I make changes? ( i mean where should I do changes ?). ","created_at":"2021-02-14T13:09:25Z","version":"1.4.1","FAIL_TO_PASS":[],"PASS_TO_PASS":[],"environment_setup_commit":"","patch":"diff --git a\/pandas\/io\/formats\/style.py b\/pandas\/io\/formats\/style.py\n--- a\/pandas\/io\/formats\/style.py\n+++ b\/pandas\/io\/formats\/style.py\n@@ -474,8 +474,15 @@ def _translate(self):\n                 )\n \n             index_header_row.extend(\n-                [{\"type\": \"th\", \"value\": BLANK_VALUE, \"class\": \" \".join([BLANK_CLASS])}]\n-                * (len(clabels[0]) - len(hidden_columns))\n+                [\n+                    {\n+                        \"type\": \"th\",\n+                        \"value\": BLANK_VALUE,\n+                        \"class\": \" \".join([BLANK_CLASS, f\"col{c}\"]),\n+                    }\n+                    for c in range(len(clabels[0]))\n+                    if c not in hidden_columns\n+                ]\n             )\n \n             head.append(index_header_row)\n"}
{"repo":"pandas-dev\/pandas","instance_id":"pandas-dev__pandas-39800","base_commit":"fc9fdba6592bdb5d0d1147ce4d65639acd897565","test_patch":"diff --git a\/pandas\/tests\/io\/excel\/test_writers.py b\/pandas\/tests\/io\/excel\/test_writers.py\n--- a\/pandas\/tests\/io\/excel\/test_writers.py\n+++ b\/pandas\/tests\/io\/excel\/test_writers.py\n@@ -1305,6 +1305,15 @@ def test_raise_when_saving_timezones(self, dtype, tz_aware_fixture, path):\n         with pytest.raises(ValueError, match=\"Excel does not support\"):\n             df.to_excel(path)\n \n+    def test_excel_duplicate_columns_with_names(self, path):\n+        # GH#39695\n+        df = DataFrame({\"A\": [0, 1], \"B\": [10, 11]})\n+        df.to_excel(path, columns=[\"A\", \"B\", \"A\"], index=False)\n+\n+        result = pd.read_excel(path)\n+        expected = DataFrame([[0, 10, 0], [1, 11, 1]], columns=[\"A\", \"B\", \"A.1\"])\n+        tm.assert_frame_equal(result, expected)\n+\n \n class TestExcelWriterEngineTests:\n     @pytest.mark.parametrize(\n","problem_statement":"BUG: DataFrame.to_excel() now raises if column parameter contains duplicates\n- [x] I have checked that this issue has not already been reported.\r\n\r\n- [x] I have confirmed this bug exists on the latest version of pandas.\r\n\r\n- [ ] (optional) I have confirmed this bug exists on the master branch of pandas.\r\n\r\n---\r\n\r\n#### Code Sample, a copy-pastable example\r\n\r\n```python\r\nimport pandas as pd\r\ndft = pd.DataFrame({\"A\": [0, 1], \"B\": [10, 11]})\r\ndft.to_excel(r\"c:\\test\\test3.xlsx\", columns=[\"A\", \"B\", \"A\"])\r\n\r\n```\r\n\r\n#### Problem description\r\n\r\nThe example works with pandas 1.1.0, but not with pandas 1.2.1 any more. With 1.2.1 it raises:\r\n\r\n```python-traceback\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"c:\\test\\venv4\\lib\\site-packages\\pandas\\core\\generic.py\", line 2177, in to_excel\r\n    formatter = ExcelFormatter(\r\n  File \"c:\\test\\venv4\\lib\\site-packages\\pandas\\io\\formats\\excel.py\", line 470, in __init__\r\n    raise KeyError(\"Not all names specified in 'columns' are found\")\r\nKeyError: \"Not all names specified in 'columns' are found\"\r\n\r\n```\r\n\r\nIf the column argument doesn't contain duplicates (e.g. `columns=[\"A\", \"B\"]`) it works also in 1.2.1\r\n\r\nIn the documentation of .to_excel() I found no information about an intended change in behaviour.\r\n\r\n#### Expected Output\r\n\r\nI expected it to work like with pandas 1.1.0, producing an excel file with the following content:\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/25440862\/107364440-ba3eec00-6adb-11eb-99c5-3abe55f07e9e.png)\r\n\r\n\r\n#### Output of ``pd.show_versions()``\r\n\r\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit           : 9d598a5e1eee26df95b3910e3f2934890d062caa\r\npython           : 3.9.1.final.0\r\npython-bits      : 64\r\nOS               : Windows\r\nOS-release       : 10\r\nVersion          : 10.0.18362\r\nmachine          : AMD64\r\nprocessor        : Intel64 Family 6 Model 142 Stepping 10, GenuineIntel\r\nbyteorder        : little\r\nLC_ALL           : None\r\nLANG             : None\r\nLOCALE           : de_DE.cp1252\r\n\r\npandas           : 1.2.1\r\nnumpy            : 1.20.0\r\npytz             : 2021.1\r\ndateutil         : 2.8.1\r\npip              : 21.0.1\r\nsetuptools       : 53.0.0\r\nCython           : None\r\npytest           : None\r\nhypothesis       : None\r\nsphinx           : None\r\nblosc            : None\r\nfeather          : None\r\nxlsxwriter       : None\r\nlxml.etree       : None\r\nhtml5lib         : None\r\npymysql          : None\r\npsycopg2         : None\r\njinja2           : None\r\nIPython          : None\r\npandas_datareader: None\r\nbs4              : None\r\nbottleneck       : None\r\nfsspec           : None\r\nfastparquet      : None\r\ngcsfs            : None\r\nmatplotlib       : None\r\nnumexpr          : None\r\nodfpy            : None\r\nopenpyxl         : 3.0.6\r\npandas_gbq       : None\r\npyarrow          : None\r\npyxlsb           : None\r\ns3fs             : None\r\nscipy            : None\r\nsqlalchemy       : None\r\ntables           : None\r\ntabulate         : None\r\nxarray           : None\r\nxlrd             : None\r\nxlwt             : None\r\nnumba            : None\r\n\r\n<\/details>\r\n\n","hints_text":"Thanks @RagBlufThim for the report! I can also reproduce this on master. \r\nThis appears to be caused by #37374. cc @jbrockmendel (https:\/\/github.com\/pandas-dev\/pandas\/blame\/879d2fb8a36cfb52e8129e60b1f808cf8937a378\/pandas\/io\/formats\/excel.py#L478)\n> The example works with pandas 1.1.0, but not with pandas 1.2.1 any more. With 1.2.1 it raises:\r\n\r\nwas also working in 1.1.4\r\n\r\nfirst bad commit: [e99e5ab32c4e831e7bbac0346189f4d6d86a6225] BUG: Fix duplicates in intersection of multiindexes (#36927) cc @phofl \r\n\r\n\nWill take a look over the weekend ","created_at":"2021-02-13T21:07:24Z","version":"1.4.1","FAIL_TO_PASS":[],"PASS_TO_PASS":[],"environment_setup_commit":"","patch":"diff --git a\/pandas\/io\/formats\/excel.py b\/pandas\/io\/formats\/excel.py\n--- a\/pandas\/io\/formats\/excel.py\n+++ b\/pandas\/io\/formats\/excel.py\n@@ -475,7 +475,7 @@ def __init__(\n             if not len(Index(cols).intersection(df.columns)):\n                 raise KeyError(\"passes columns are not ALL present dataframe\")\n \n-            if len(Index(cols).intersection(df.columns)) != len(cols):\n+            if len(Index(cols).intersection(df.columns)) != len(set(cols)):\n                 # Deprecated in GH#17295, enforced in 1.0.0\n                 raise KeyError(\"Not all names specified in 'columns' are found\")\n \n"}
{"repo":"pandas-dev\/pandas","instance_id":"pandas-dev__pandas-39796","base_commit":"fc9fdba6592bdb5d0d1147ce4d65639acd897565","test_patch":"diff --git a\/pandas\/tests\/io\/excel\/test_readers.py b\/pandas\/tests\/io\/excel\/test_readers.py\n--- a\/pandas\/tests\/io\/excel\/test_readers.py\n+++ b\/pandas\/tests\/io\/excel\/test_readers.py\n@@ -117,6 +117,30 @@ def cd_and_set_engine(self, engine, datapath, monkeypatch):\n         monkeypatch.chdir(datapath(\"io\", \"data\", \"excel\"))\n         monkeypatch.setattr(pd, \"read_excel\", func)\n \n+    def test_engine_used(self, read_ext, engine, monkeypatch):\n+        # GH 38884\n+        def parser(self, *args, **kwargs):\n+            return self.engine\n+\n+        monkeypatch.setattr(pd.ExcelFile, \"parse\", parser)\n+\n+        expected_defaults = {\n+            \"xlsx\": \"openpyxl\",\n+            \"xlsm\": \"openpyxl\",\n+            \"xlsb\": \"pyxlsb\",\n+            \"xls\": \"xlrd\",\n+            \"ods\": \"odf\",\n+        }\n+\n+        with open(\"test1\" + read_ext, \"rb\") as f:\n+            result = pd.read_excel(f)\n+\n+        if engine is not None:\n+            expected = engine\n+        else:\n+            expected = expected_defaults[read_ext[1:]]\n+        assert result == expected\n+\n     def test_usecols_int(self, read_ext, df_ref):\n         df_ref = df_ref.reindex(columns=[\"A\", \"B\", \"C\"])\n \n@@ -1164,6 +1188,24 @@ def cd_and_set_engine(self, engine, datapath, monkeypatch):\n         monkeypatch.chdir(datapath(\"io\", \"data\", \"excel\"))\n         monkeypatch.setattr(pd, \"ExcelFile\", func)\n \n+    def test_engine_used(self, read_ext, engine, monkeypatch):\n+        expected_defaults = {\n+            \"xlsx\": \"openpyxl\",\n+            \"xlsm\": \"openpyxl\",\n+            \"xlsb\": \"pyxlsb\",\n+            \"xls\": \"xlrd\",\n+            \"ods\": \"odf\",\n+        }\n+\n+        with pd.ExcelFile(\"test1\" + read_ext) as excel:\n+            result = excel.engine\n+\n+        if engine is not None:\n+            expected = engine\n+        else:\n+            expected = expected_defaults[read_ext[1:]]\n+        assert result == expected\n+\n     def test_excel_passes_na(self, read_ext):\n         with pd.ExcelFile(\"test4\" + read_ext) as excel:\n             parsed = pd.read_excel(\n","problem_statement":"DEPR: Remove xlrd as being the default reader for xlsx\nCurrently the default reader for xlsx is openpyxl if installed, otherwise it is xlrd. While xlrd == 1.2.0 will work with xlsx files, xlrd >= 2.0 will not. In pandas 1.2, a FutureWarning is raised if xlrd is used on non-xls files. We should remove xlrd as being the default for xlsx files in pandas 2.0, but perhaps even 1.3 (if 1.3 != 2.0).\r\n\r\ncc @jorisvandenbossche\n","hints_text":"I'm thinking we should do this for 1.3, but want to make sure others don't think that's too soon before putting up a PR.\nit's ok to do this for 1.3\nxlrd broke things and no reason to go to great lengths to support ","created_at":"2021-02-13T16:41:32Z","version":"1.4.1","FAIL_TO_PASS":[],"PASS_TO_PASS":[],"environment_setup_commit":"","patch":"diff --git a\/pandas\/io\/excel\/_base.py b\/pandas\/io\/excel\/_base.py\n--- a\/pandas\/io\/excel\/_base.py\n+++ b\/pandas\/io\/excel\/_base.py\n@@ -129,11 +129,9 @@\n          ``pyxlsb`` will be used.\n \n          .. versionadded:: 1.3.0\n-       - Otherwise if `openpyxl <https:\/\/pypi.org\/project\/openpyxl\/>`_ is installed,\n-         then ``openpyxl`` will be used.\n-       - Otherwise if ``xlrd >= 2.0`` is installed, a ``ValueError`` will be raised.\n-       - Otherwise ``xlrd`` will be used and a ``FutureWarning`` will be raised. This\n-         case will raise a ``ValueError`` in a future version of pandas.\n+       - Otherwise ``openpyxl`` will be used.\n+\n+         .. versionchanged:: 1.3.0\n \n converters : dict, default None\n     Dict of functions for converting values in certain columns. Keys can\n@@ -997,7 +995,7 @@ class ExcelFile:\n     Parameters\n     ----------\n     path_or_buffer : str, path object (pathlib.Path or py._path.local.LocalPath),\n-        a file-like object, xlrd workbook or openpypl workbook.\n+        a file-like object, xlrd workbook or openpyxl workbook.\n         If a string or path object, expected to be a path to a\n         .xls, .xlsx, .xlsb, .xlsm, .odf, .ods, or .odt file.\n     engine : str, default None\n@@ -1111,9 +1109,7 @@ def __init__(\n                     stacklevel = 2\n                 warnings.warn(\n                     f\"Your version of xlrd is {xlrd_version}. In xlrd >= 2.0, \"\n-                    f\"only the xls format is supported. As a result, the \"\n-                    f\"openpyxl engine will be used if it is installed and the \"\n-                    f\"engine argument is not specified. Install \"\n+                    f\"only the xls format is supported. Install \"\n                     f\"openpyxl instead.\",\n                     FutureWarning,\n                     stacklevel=stacklevel,\ndiff --git a\/pandas\/io\/excel\/_util.py b\/pandas\/io\/excel\/_util.py\n--- a\/pandas\/io\/excel\/_util.py\n+++ b\/pandas\/io\/excel\/_util.py\n@@ -62,13 +62,6 @@ def get_default_engine(ext, mode=\"reader\"):\n             _default_writers[\"xlsx\"] = \"xlsxwriter\"\n         return _default_writers[ext]\n     else:\n-        if (\n-            import_optional_dependency(\"openpyxl\", errors=\"ignore\") is None\n-            and import_optional_dependency(\"xlrd\", errors=\"ignore\") is not None\n-        ):\n-            # if no openpyxl but xlrd installed, return xlrd\n-            # the version is handled elsewhere\n-            _default_readers[\"xlsx\"] = \"xlrd\"\n         return _default_readers[ext]\n \n \n"}
{"repo":"pandas-dev\/pandas","instance_id":"pandas-dev__pandas-39777","base_commit":"c29facced7a2d39d07d42ffbf2b5d4e39fd4ba99","test_patch":"diff --git a\/pandas\/tests\/io\/parser\/common\/test_common_basic.py b\/pandas\/tests\/io\/parser\/common\/test_common_basic.py\n--- a\/pandas\/tests\/io\/parser\/common\/test_common_basic.py\n+++ b\/pandas\/tests\/io\/parser\/common\/test_common_basic.py\n@@ -6,6 +6,7 @@\n from inspect import signature\n from io import StringIO\n import os\n+from pathlib import Path\n \n import numpy as np\n import pytest\n@@ -734,3 +735,21 @@ def test_dict_keys_as_names(all_parsers):\n     result = parser.read_csv(StringIO(data), names=keys)\n     expected = DataFrame({\"a\": [1], \"b\": [2]})\n     tm.assert_frame_equal(result, expected)\n+\n+\n+def test_encoding_surrogatepass(all_parsers):\n+    # GH39017\n+    parser = all_parsers\n+    content = b\"\\xed\\xbd\\xbf\"\n+    decoded = content.decode(\"utf-8\", errors=\"surrogatepass\")\n+    expected = DataFrame({decoded: [decoded]}, index=[decoded * 2])\n+    expected.index.name = decoded * 2\n+\n+    with tm.ensure_clean() as path:\n+        Path(path).write_bytes(\n+            content * 2 + b\",\" + content + b\"\\n\" + content * 2 + b\",\" + content\n+        )\n+        df = parser.read_csv(path, encoding_errors=\"surrogatepass\", index_col=0)\n+        tm.assert_frame_equal(df, expected)\n+        with pytest.raises(UnicodeDecodeError, match=\"'utf-8' codec can't decode byte\"):\n+            parser.read_csv(path)\ndiff --git a\/pandas\/tests\/io\/parser\/common\/test_read_errors.py b\/pandas\/tests\/io\/parser\/common\/test_read_errors.py\n--- a\/pandas\/tests\/io\/parser\/common\/test_read_errors.py\n+++ b\/pandas\/tests\/io\/parser\/common\/test_read_errors.py\n@@ -232,5 +232,5 @@ def test_open_file(all_parsers):\n         warnings.simplefilter(\"always\", category=ResourceWarning)\n         with warnings.catch_warnings(record=True) as record:\n             with pytest.raises(csv.Error, match=\"Could not determine delimiter\"):\n-                parser.read_csv(file, sep=None)\n+                parser.read_csv(file, sep=None, encoding_errors=\"replace\")\n             assert len(record) == 0, record[0].message\ndiff --git a\/pandas\/tests\/io\/test_common.py b\/pandas\/tests\/io\/test_common.py\n--- a\/pandas\/tests\/io\/test_common.py\n+++ b\/pandas\/tests\/io\/test_common.py\n@@ -2,6 +2,7 @@\n Tests for the pandas.io.common functionalities\n \"\"\"\n import codecs\n+from functools import partial\n from io import (\n     BytesIO,\n     StringIO,\n@@ -429,14 +430,6 @@ def test_is_fsspec_url():\n     assert not icom.is_fsspec_url(\"relative\/local\/path\")\n \n \n-def test_default_errors():\n-    # GH 38989\n-    with tm.ensure_clean() as path:\n-        file = Path(path)\n-        file.write_bytes(b\"\\xe4\\na\\n1\")\n-        tm.assert_frame_equal(pd.read_csv(file, skiprows=[0]), pd.DataFrame({\"a\": [1]}))\n-\n-\n @pytest.mark.parametrize(\"encoding\", [None, \"utf-8\"])\n @pytest.mark.parametrize(\"format\", [\"csv\", \"json\"])\n def test_codecs_encoding(encoding, format):\n@@ -481,3 +474,46 @@ def test_explicit_encoding(io_class, mode, msg):\n     with io_class() as buffer:\n         with pytest.raises(TypeError, match=msg):\n             expected.to_csv(buffer, mode=f\"w{mode}\")\n+\n+\n+@pytest.mark.parametrize(\"encoding_errors\", [None, \"strict\", \"replace\"])\n+@pytest.mark.parametrize(\"format\", [\"csv\", \"json\"])\n+def test_encoding_errors(encoding_errors, format):\n+    # GH39450\n+    msg = \"'utf-8' codec can't decode byte\"\n+    bad_encoding = b\"\\xe4\"\n+\n+    if format == \"csv\":\n+        return\n+        content = bad_encoding + b\"\\n\" + bad_encoding\n+        reader = pd.read_csv\n+    else:\n+        content = (\n+            b'{\"'\n+            + bad_encoding * 2\n+            + b'\": {\"'\n+            + bad_encoding\n+            + b'\":\"'\n+            + bad_encoding\n+            + b'\"}}'\n+        )\n+        reader = partial(pd.read_json, orient=\"index\")\n+    with tm.ensure_clean() as path:\n+        file = Path(path)\n+        file.write_bytes(content)\n+\n+        if encoding_errors != \"replace\":\n+            with pytest.raises(UnicodeDecodeError, match=msg):\n+                reader(path, encoding_errors=encoding_errors)\n+        else:\n+            df = reader(path, encoding_errors=encoding_errors)\n+            decoded = bad_encoding.decode(errors=encoding_errors)\n+            expected = pd.DataFrame({decoded: [decoded]}, index=[decoded * 2])\n+            tm.assert_frame_equal(df, expected)\n+\n+\n+def test_bad_encdoing_errors():\n+    # GH 39777\n+    with tm.ensure_clean() as path:\n+        with pytest.raises(ValueError, match=\"Invalid value for `encoding_errors`\"):\n+            icom.get_handle(path, \"w\", errors=\"bad\")\n","problem_statement":"ENH: Add encoding errors option in pandas.read_csv\n#### Related to problem:\r\n\r\n```python\r\ndf.to_csv('abc.csv', errors='surrogatepass')   # saving works fine.\r\n\r\n# Try to load:\r\n\r\n# Attempt 1:\r\npd.read_csv('abc.csv') \r\n# Fails.    UnicodeEncodeError: 'utf-8' codec can't encode characters in position 30682-30685: surrogates not allowed\r\n\r\n# Attempt 2:\r\npd.read_csv('abc.csv', errors='surrogatepass') \r\n# Fails. No `errors` parameter.\r\n\r\n# Attempt 3:\r\nwith open('abc.csv', errors='surrogatepass') as _file:\r\n    df = pd.read_csv(_file)\r\n# Fails.    UnicodeEncodeError: 'utf-8' codec can't encode characters in position 30682-30685: surrogates not allowed\r\n```\r\n\r\n#### Describe the solution you'd like\r\n\r\nRecently, we added `errors` as a function parameter to `to_csv` in this [merged PR](https:\/\/github.com\/pandas-dev\/pandas\/pull\/27899). Can we do the same for `read_csv`? This solution would make Attempt 2 work.\r\n\r\n(Not sure why Attempt 3 doesn't work since `read_csv` accepts a file handler object.)\r\n\r\n#### API breaking implications\r\n\r\nShould not break.\r\n\r\n#### Describe alternatives you've considered\r\n\r\nsee (futile) Attempt 3 above.\r\n\r\n#### Additional context\r\n\r\nSection \"Error handlers\" in https:\/\/docs.python.org\/3\/library\/codecs.html says:\r\n\r\n<img width=\"681\" alt=\"Screenshot 2021-01-07 at 7 57 20 PM\" src=\"https:\/\/user-images.githubusercontent.com\/1690072\/103890172-91b18400-5122-11eb-8475-dbaa6738bdff.png\">\r\n\r\nExample of encoding & decoding:\r\n\r\n```python\r\nx=\"\\ud83d\\ude4f\".encode('utf-16', 'surrogatepass').decode('utf-16')\r\nprint(x)\r\n# prints \ud83d\ude4f\r\n```\r\n\n","hints_text":"","created_at":"2021-02-12T14:06:32Z","version":"1.4.1","FAIL_TO_PASS":[],"PASS_TO_PASS":[],"environment_setup_commit":"","patch":"diff --git a\/pandas\/io\/common.py b\/pandas\/io\/common.py\n--- a\/pandas\/io\/common.py\n+++ b\/pandas\/io\/common.py\n@@ -583,12 +583,32 @@ def get_handle(\n     Returns the dataclass IOHandles\n     \"\"\"\n     # Windows does not default to utf-8. Set to utf-8 for a consistent behavior\n-    encoding_passed, encoding = encoding, encoding or \"utf-8\"\n+    encoding = encoding or \"utf-8\"\n \n     # read_csv does not know whether the buffer is opened in binary\/text mode\n     if _is_binary_mode(path_or_buf, mode) and \"b\" not in mode:\n         mode += \"b\"\n \n+    # valdiate errors\n+    if isinstance(errors, str):\n+        errors = errors.lower()\n+    if errors not in (\n+        None,\n+        \"strict\",\n+        \"ignore\",\n+        \"replace\",\n+        \"xmlcharrefreplace\",\n+        \"backslashreplace\",\n+        \"namereplace\",\n+        \"surrogateescape\",\n+        \"surrogatepass\",\n+    ):\n+        raise ValueError(\n+            f\"Invalid value for `encoding_errors` ({errors}). Please see \"\n+            + \"https:\/\/docs.python.org\/3\/library\/codecs.html#error-handlers \"\n+            + \"for valid values.\"\n+        )\n+\n     # open URLs\n     ioargs = _get_filepath_or_buffer(\n         path_or_buf,\n@@ -677,9 +697,6 @@ def get_handle(\n         # Check whether the filename is to be opened in binary mode.\n         # Binary mode does not support 'encoding' and 'newline'.\n         if ioargs.encoding and \"b\" not in ioargs.mode:\n-            if errors is None and encoding_passed is None:\n-                # ignore errors when no encoding is specified\n-                errors = \"replace\"\n             # Encoding\n             handle = open(\n                 handle,\ndiff --git a\/pandas\/io\/json\/_json.py b\/pandas\/io\/json\/_json.py\n--- a\/pandas\/io\/json\/_json.py\n+++ b\/pandas\/io\/json\/_json.py\n@@ -334,6 +334,7 @@ def read_json(\n     precise_float: bool = False,\n     date_unit=None,\n     encoding=None,\n+    encoding_errors: Optional[str] = \"strict\",\n     lines: bool = False,\n     chunksize: Optional[int] = None,\n     compression: CompressionOptions = \"infer\",\n@@ -456,6 +457,12 @@ def read_json(\n     encoding : str, default is 'utf-8'\n         The encoding to use to decode py3 bytes.\n \n+    encoding_errors : str, optional, default \"strict\"\n+        How encoding errors are treated. `List of possible values\n+        <https:\/\/docs.python.org\/3\/library\/codecs.html#error-handlers>`_ .\n+\n+        .. versionadded:: 1.3\n+\n     lines : bool, default False\n         Read the file as a json object per line.\n \n@@ -584,6 +591,7 @@ def read_json(\n         compression=compression,\n         nrows=nrows,\n         storage_options=storage_options,\n+        encoding_errors=encoding_errors,\n     )\n \n     if chunksize:\n@@ -620,6 +628,7 @@ def __init__(\n         compression: CompressionOptions,\n         nrows: Optional[int],\n         storage_options: StorageOptions = None,\n+        encoding_errors: Optional[str] = \"strict\",\n     ):\n \n         self.orient = orient\n@@ -638,6 +647,7 @@ def __init__(\n         self.chunksize = chunksize\n         self.nrows_seen = 0\n         self.nrows = nrows\n+        self.encoding_errors = encoding_errors\n         self.handles: Optional[IOHandles] = None\n \n         if self.chunksize is not None:\n@@ -661,8 +671,8 @@ def _preprocess_data(self, data):\n         Otherwise, we read it into memory for the `read` method.\n         \"\"\"\n         if hasattr(data, \"read\") and not (self.chunksize or self.nrows):\n-            data = data.read()\n-            self.close()\n+            with self:\n+                data = data.read()\n         if not hasattr(data, \"read\") and (self.chunksize or self.nrows):\n             data = StringIO(data)\n \n@@ -692,6 +702,7 @@ def _get_data_from_filepath(self, filepath_or_buffer):\n                 encoding=self.encoding,\n                 compression=self.compression,\n                 storage_options=self.storage_options,\n+                errors=self.encoding_errors,\n             )\n             filepath_or_buffer = self.handles.handle\n \ndiff --git a\/pandas\/io\/parsers\/base_parser.py b\/pandas\/io\/parsers\/base_parser.py\n--- a\/pandas\/io\/parsers\/base_parser.py\n+++ b\/pandas\/io\/parsers\/base_parser.py\n@@ -109,6 +109,7 @@\n     \"mangle_dupe_cols\": True,\n     \"infer_datetime_format\": False,\n     \"skip_blank_lines\": True,\n+    \"encoding_errors\": \"strict\",\n }\n \n \n@@ -212,6 +213,7 @@ def _open_handles(self, src: FilePathOrBuffer, kwds: Dict[str, Any]) -> None:\n             compression=kwds.get(\"compression\", None),\n             memory_map=kwds.get(\"memory_map\", False),\n             storage_options=kwds.get(\"storage_options\", None),\n+            errors=kwds.get(\"encoding_errors\", \"strict\"),\n         )\n \n     def _validate_parse_dates_presence(self, columns: List[str]) -> None:\ndiff --git a\/pandas\/io\/parsers\/readers.py b\/pandas\/io\/parsers\/readers.py\n--- a\/pandas\/io\/parsers\/readers.py\n+++ b\/pandas\/io\/parsers\/readers.py\n@@ -296,11 +296,24 @@\n     Encoding to use for UTF when reading\/writing (ex. 'utf-8'). `List of Python\n     standard encodings\n     <https:\/\/docs.python.org\/3\/library\/codecs.html#standard-encodings>`_ .\n+\n     .. versionchanged:: 1.2\n \n        When ``encoding`` is ``None``, ``errors=\"replace\"`` is passed to\n        ``open()``. Otherwise, ``errors=\"strict\"`` is passed to ``open()``.\n        This behavior was previously only the case for ``engine=\"python\"``.\n+\n+    .. versionchanged:: 1.3\n+\n+       ``encoding_errors`` is a new argument. ``encoding`` has no longer an\n+       influence on how encoding errors are handled.\n+\n+encoding_errors : str, optional, default \"strict\"\n+    How encoding errors are treated. `List of possible values\n+    <https:\/\/docs.python.org\/3\/library\/codecs.html#error-handlers>`_ .\n+\n+    .. versionadded:: 1.3\n+\n dialect : str or csv.Dialect, optional\n     If provided, this parameter will override values (default or not) for the\n     following parameters: `delimiter`, `doublequote`, `escapechar`,\n@@ -515,6 +528,7 @@ def read_csv(\n     escapechar=None,\n     comment=None,\n     encoding=None,\n+    encoding_errors: Optional[str] = \"strict\",\n     dialect=None,\n     # Error Handling\n     error_bad_lines=True,\n@@ -599,6 +613,7 @@ def read_table(\n     # Error Handling\n     error_bad_lines=True,\n     warn_bad_lines=True,\n+    encoding_errors: Optional[str] = \"strict\",\n     # Internal\n     delim_whitespace=False,\n     low_memory=_c_parser_defaults[\"low_memory\"],\n"}
{"repo":"pandas-dev\/pandas","instance_id":"pandas-dev__pandas-39766","base_commit":"75609da1dfcf136f9a6e2f37eff5809cacde2925","test_patch":"diff --git a\/pandas\/tests\/util\/test_show_versions.py b\/pandas\/tests\/util\/test_show_versions.py\n--- a\/pandas\/tests\/util\/test_show_versions.py\n+++ b\/pandas\/tests\/util\/test_show_versions.py\n@@ -1,7 +1,14 @@\n+import json\n+import os\n import re\n \n import pytest\n \n+from pandas.util._print_versions import (\n+    _get_dependency_info,\n+    _get_sys_info,\n+)\n+\n import pandas as pd\n \n \n@@ -26,11 +33,47 @@\n     \"ignore:Distutils:UserWarning\"\n )\n @pytest.mark.filterwarnings(\"ignore:Setuptools is replacing distutils:UserWarning\")\n-def test_show_versions(capsys):\n+def test_show_versions(tmpdir):\n+    # GH39701\n+    as_json = os.path.join(tmpdir, \"test_output.json\")\n+\n+    pd.show_versions(as_json=as_json)\n+\n+    with open(as_json) as fd:\n+        # check if file output is valid JSON, will raise an exception if not\n+        result = json.load(fd)\n+\n+    # Basic check that each version element is found in output\n+    expected = {\n+        \"system\": _get_sys_info(),\n+        \"dependencies\": _get_dependency_info(),\n+    }\n+\n+    assert result == expected\n+\n+\n+def test_show_versions_console_json(capsys):\n+    # GH39701\n+    pd.show_versions(as_json=True)\n+    stdout = capsys.readouterr().out\n+\n+    # check valid json is printed to the console if as_json is True\n+    result = json.loads(stdout)\n+\n+    # Basic check that each version element is found in output\n+    expected = {\n+        \"system\": _get_sys_info(),\n+        \"dependencies\": _get_dependency_info(),\n+    }\n+\n+    assert result == expected\n+\n+\n+def test_show_versions_console(capsys):\n+    # gh-32041\n     # gh-32041\n-    pd.show_versions()\n-    captured = capsys.readouterr()\n-    result = captured.out\n+    pd.show_versions(as_json=False)\n+    result = capsys.readouterr().out\n \n     # check header\n     assert \"INSTALLED VERSIONS\" in result\n@@ -44,3 +87,16 @@ def test_show_versions(capsys):\n \n     # check optional dependency\n     assert re.search(r\"pyarrow\\s*:\\s([0-9\\.]+|None)\\n\", result)\n+\n+\n+def test_json_output_match(capsys, tmpdir):\n+    # GH39701\n+    pd.show_versions(as_json=True)\n+    result_console = capsys.readouterr().out\n+\n+    out_path = os.path.join(tmpdir, \"test_json.json\")\n+    pd.show_versions(as_json=out_path)\n+    with open(out_path) as out_fd:\n+        result_file = out_fd.read()\n+\n+    assert result_console == result_file\n","problem_statement":"BUG: pd.show_versions: json.decoder.JSONDecodeError\n- [x] I have checked that this issue has not already been reported.\r\n\r\n- [x] I have confirmed this bug exists on the latest version of pandas.\r\n\r\n- [ ] (optional) I have confirmed this bug exists on the master branch of pandas.\r\n\r\n---\r\n\r\n**Note**: Please read [this guide](https:\/\/matthewrocklin.com\/blog\/work\/2018\/02\/28\/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug.\r\n\r\n#### Code Sample, a copy-pastable example\r\n\r\n```python\r\nimport contextlib, io, json\r\nimport pandas as pd\r\n\r\nredirect = io.StringIO()\r\nwith contextlib.redirect_stdout(redirect):\r\n    pd.show_versions(as_json=True)  # produces invalid json\r\npd_versions = redirect.getvalue()\r\npd_versions = json.loads(pd_versions)  # raises JSONDecodeError\r\n```\r\n\r\n#### Problem description\r\n\r\n`pd.show_versions(as_json=True)` is supposed to print valid JSON, but it really doesn't. It is supposed to work as advertised but it doesn't. It prints invalid JSON that is not parsable. The following error is printed when attempting to parse it:\r\n\r\n> json.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\r\n\r\nThis functionality is important because when running a job in the cloud, it is not feasible to print a multiline output. This is because every printed line has significant attached metadata. It is better to have valid JSON output instead in this case. The implementation of the `show_versions` function looks to be very hacky and poorly reviewed, given that it fails in this very basic way.\r\n\r\n#### Expected Output\r\n\r\nIn the code example, `json.loads(pd_versions)` should have been able to parse the captured text.\r\n\r\n#### Output of ``pd.show_versions()``\r\n\r\n<details>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit           : 7d32926db8f7541c356066dcadabf854487738de\r\npython           : 3.8.6.final.0\r\npython-bits      : 64\r\nOS               : Darwin\r\nOS-release       : 19.6.0\r\nVersion          : Darwin Kernel Version 19.6.0: Tue Nov 10 00:10:30 PST 2020; root:xnu-6153.141.10~1\/RELEASE_X86_64\r\nmachine          : x86_64\r\nprocessor        : i386\r\nbyteorder        : little\r\nLC_ALL           : None\r\nLANG             : None\r\nLOCALE           : en_US.UTF-8\r\npandas           : 1.2.2\r\nnumpy            : 1.19.4\r\npytz             : 2020.4\r\ndateutil         : 2.8.1\r\npip              : 21.0.1\r\nsetuptools       : 50.3.2\r\nCython           : None\r\npytest           : 6.2.2\r\nhypothesis       : None\r\nsphinx           : None\r\nblosc            : None\r\nfeather          : None\r\nxlsxwriter       : None\r\nlxml.etree       : None\r\nhtml5lib         : None\r\npymysql          : None\r\npsycopg2         : None\r\njinja2           : None\r\nIPython          : None\r\npandas_datareader: None\r\nbs4              : None\r\nbottleneck       : None\r\nfsspec           : None\r\nfastparquet      : None\r\ngcsfs            : None\r\nmatplotlib       : None\r\nnumexpr          : None\r\nodfpy            : None\r\nopenpyxl         : None\r\npandas_gbq       : None\r\npyarrow          : 3.0.0\r\npyxlsb           : None\r\ns3fs             : None\r\nscipy            : None\r\nsqlalchemy       : None\r\ntables           : None\r\ntabulate         : None\r\nxarray           : None\r\nxlrd             : None\r\nxlwt             : None\r\nnumba            : None\r\n\r\n<\/details>\r\n\n","hints_text":"> The implementation of the `show_versions` function looks to be very hacky and poorly reviewed, given that it fails in this very basic way.\r\n\r\nPRs and contributions always welcome.\n@impredicative I can reproduce this on master. Looks like https:\/\/github.com\/pandas-dev\/pandas\/blob\/ddbf3771db13d927bb6d862e10c08b1c14e8d005\/pandas\/util\/_print_versions.py#L110 should be ```print(json.dumps(j))``` instead. \n> @impredicative I can reproduce this on master. Looks like\r\n> \r\n> https:\/\/github.com\/pandas-dev\/pandas\/blob\/ddbf3771db13d927bb6d862e10c08b1c14e8d005\/pandas\/util\/_print_versions.py#L110\r\n> should be `print(json.dumps(j))` instead.\r\n\r\nI tested this locally and json.loads() now executes without error. I'm unsure about how to contribute but I'd be happy to try and submit a PR on this.\n> It would really be better to return a JSON object. It makes no practical sense to print it. Printing the JSON didn't work to begin with, so no existing functionality will be broken by this change.\r\n\r\nBy JSON object do you mean a valid JSON dictionary as a Python string ? It would make this function either return a value or perform an action depending on wether as_json is True or False, which I do not think is desirable. Instead, it could be changed such that a value is printed and then returned. I do not think that this would break any existing code.","created_at":"2021-02-12T01:18:28Z","version":"1.4.1","FAIL_TO_PASS":[],"PASS_TO_PASS":[],"environment_setup_commit":"","patch":"diff --git a\/pandas\/util\/_print_versions.py b\/pandas\/util\/_print_versions.py\n--- a\/pandas\/util\/_print_versions.py\n+++ b\/pandas\/util\/_print_versions.py\n@@ -115,7 +115,7 @@ def show_versions(as_json: Union[str, bool] = False) -> None:\n         j = {\"system\": sys_info, \"dependencies\": deps}\n \n         if as_json is True:\n-            print(j)\n+            sys.stdout.writelines(json.dumps(j, indent=2))\n         else:\n             assert isinstance(as_json, str)  # needed for mypy\n             with codecs.open(as_json, \"wb\", encoding=\"utf8\") as f:\n"}
